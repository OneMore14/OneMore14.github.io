---
layout: post
title:  "The Design of a Practical System for Fault-Tolerant Virtual Machines"
date:   2021-11-29 16:34:01 +0800
categories: 6.824
---


## 1. INTRODUCTION

常见的容灾服务器实现方法是主从备份，起一台备份机，不间断地将主机的状态、操作等备份到备用机。这样可以快速从主机切换到备用机，但代价是同步状态非常消耗带宽。

另一种使用少量带宽的方法是 state-machine approach。核心思想是将一堆服务器看作deterministic state machines，这些自动机从相同的初始状态启动，然后互相同步保证它们按同样的顺序接收同样的请求。然而大多数servers或者services都有nondeterministic operation，因此需要额外的调节保证主从一致性，但这些额外的信息远比在primary中变化的状态少。



## 2. BASIC FT DESIGN

![image-20211129170742064](/assets/2021/11/vmft/image-20211129170742064.png)

图一显示了容错VM的基本结构，有一个Primary VM，在另一台物理机器上启动Backup VM，两个VM共享一块硬盘。在整个网络中只有primary vm才宣布自己的存在，所有的输入也是给到primary vm

所有primary vm的输入通过网络连接logging channel传给备用机。备用机执行和primary vm一样的操作，但备份机的输出会被hypervisor丢弃，因此给client返回的数据一定来自primary。primary和backup遵循特殊的协议，保证如果primary宕机，也不会有数据丢失。

检测primary或backup是否宕机的方式是，结合心跳检测和监视logging channel的流量。此外，需要保证primary和backup失去连接后，二者中只有一个继续接管工作。

### 2.1 Deterministic Replay Implementation

前面说过，将把VM当做确定状态机，这种方法面临3个挑战

1. 正确捕捉所有输入和非确定因素保证backup vm的确定性执行
2. 正确应用捕捉的输入到backup vm
3. 上述操作不能影响性能

此外，x86处理器有很多undefined side effects，因此捕捉和重放这些side effects也是一种挑战。

这些功能在VMware vSphere平台已经高效实现，捕捉到的虚拟机输入写在log中，通过读取log可以实现重放

### 2.2 FT Protocol

需要将primary VM的操作写入日志，但日志并不保存在磁盘，而是通过log channel发送给backup vm。backup实时回放这些操作，因此backup vm和primary vm是一样的。但这种机制需要确保logging channel上的传输协议能支持容错，基本要求如下

* Output Requirement: 如果backup vm接管primary，那么对外界的输出需要满足和primary完全一致

注意当失败发生后，backup开始执行的状态会和primary当时的状态很不一样，因为在执行中有很多不确定事件发生。但是，只要backup满足output requirement，外部的client不会观察到变化。

Output Requirement在以下条件可以满足： 延迟所有对外部的输出(比如一个网络包)，直到backup有足够的信息也能生成该外部输出。一个必要条件是backup已经收到了所有关于该外部输出的日志。但是，如果primary在执行输出后立即失败了，这时backup需要重放已经收到的日志然后接管系统，如果接受到的日志只能重放到执行输出前，那么此后backup的输出可能和primary的输出不一样(有非确定性因素影响)。为了解决这个问题，系统在每次输出操作时都创建一种新的日志，并规定以下输出规则

* Output Rule： primary不能发送输出到外部世界，直到backup已经接受并确认了发送输出的日志



![image-20211201192825043](/assets/2021/11/vmft/image-20211201192825043.png)

### 2.3 Detecting and Responding to Failure

* go live: 退出recording mode， 停止向logging channel发消息

如果backup宕机，primary将go live且正常执行。如果master宕机，backup也将go live，但过程会略复杂: backup的状态会迟缓于primary，backup会接受且确认一些日志，但还没有来得及回放这些日志。backup需要持续回放直到最后的log entry，之后backup将停止重放并且像普通机器一样执行，backup也就变成了一个primary VM。新的primary VM需要执行一些特定的硬件操作，比如公布自己的Mac地址等。

VMware FT使用UDP心跳检测来探测服务器宕机，同时检测primary发给backup的日志流量和backup发给primary的确认。因为有regular timer interrupts，所以logging traffic是不会断的，如果心跳或者logging traffic中断时间达到某个设定值，那就认为有机器宕机了。

但是，这种检测方法涉及到脑裂问题。当backup收不到primary的日志时，backup认为primary挂了，然后启动go live步骤，自己成为primary。但实际上，有可能只是二者间的通讯断了，primary本身还在正常工作，这时候相当于有两个primary存在，存在问题。因此在检测到宕机时，必须保证只有一个primary在继续工作。为了解决脑裂问题，我们利用VM的共享存储。当primary或backup准备go live时，首先在共享存储上执行test-and-set原子操作。如果执行成功，则继续go live步骤；如果失败，说明有其他VM已经go live了，于是终止自己的执行(commits suicide)。如果VM不能访问共享存储，则一直等待直到可以访问。

并且当一个VM启动go live步骤后，会在另外一台机器上再启动一个backup。

## 3. PRACTICAL IMPLEMENTATION OF FT

### 3.1 Starting and Restarting FT VMs

如何让启动的backup状态和primary一样也是一个大问题。这里直接借用VMware vSphere的功能，能迁移一个正在运行的VM到另一台服务器，暂停的时间在1秒以内。修改后直接克隆一个正在运行的VM。VM运行在一个集群上，当需要一个新的backup时，集群服务选择一个最好的服务器来运行

### 3.2 Managing the Logging Channel

在作者的实现中，宿主机为primary和backup的logging channel维护了一个大容量buffer

![image-20211201211116493](/assets/2021/11/vmft/image-20211201211116493.png)

primary的log buffer慢的时候，primary会停止执行，影响到与client的通信，因此要小心设计buffer大小，避免primary暂停。同时如果backup和primary之间的差距过大，也会通过减少primary的CPU时间来保证primary和backup的差距在一定时间段内。

### 3.3 Operation on FT VMs

另一个问题是处理应用在primary上的各种控制操作，比如primary被主动关机后，backup也应该关机而不是go live。资源管理的变化(比如增加primary的CPU时间份额)也应当应用到backup上。这些特殊控制也是通过logging channel由primary传给backup。

primary的VMotion比普通的迁移复杂一些，backup需要断开与primary的连接，然后在合适的时间连接迁移后的primary。VM迁移的时候需要暂停外部IO，primary VM可以直接暂停，backup却需要不断重复log中的操作，于是backup迁移时通知primary暂停IO，backup自己自然也暂停了IO。

### 3.4 Implementation Issues for Disk IOs

TODO

### 3.5 Implementation Issues for Network IO

TODO


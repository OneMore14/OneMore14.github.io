---
layout: post
title:  "计算机网络"
date:   2024-05-10 10:43:01 +0800
tags: network
typora-root-url: ../../../
---

### 1. 网络调优

网络可以调节的参数非常多，比如设置多队列，调整网卡RingBuffer大小，端口号范围，分配给软中断的CPU分片时间，选用不同的TCP拥塞控制算法，调整backlog控制半/全连接参数，控制TCP分段大小不超过MTU, TCP_NODELAY等等，但是有没有实际效果一定是测量后说了算。

可参考 [Chapter 31. Tuning the network performance](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/monitoring_and_managing_system_status_and_performance/tuning-the-network-performance_monitoring-and-managing-system-status-and-performance#doc-wrapper) 或者 ```/proc/sys/net/ipv4``` 

除了更改配置以外，可以使用 DPDK 等技术直接绕过内核，自己实现协议栈。



### 2. TCP

TCP实现其实和“八股文”里背诵的内容有很多不一样了，不过核心思想没变，主要是一些性能优化。

[TCP Fast Open](https://lwn.net/Articles/508865/) 需要客户端，服务端两边都配置，通过cookie机制可以在握手阶段发送数据

[Recent Acknowledgment (RACK)](https://datatracker.ietf.org/doc/rfc8985/) 通过包的发送时间来确认是否丢失，而不是像dupACK只看包的序列号，Linux默认开启RACK，```/proc/sys/net/ipv4/tcp_recovery``` 值默认为1

[Selective Acknowledgment (SACK)](https://datatracker.ietf.org/doc/html/rfc2018) 利用TCP header Option的部分，告诉发送方自己已经收到了哪些连续的字节流，比如ACK是10，SACK中记录已经收到15-20的字节，那么发送方只需要发送11到14的数据。(QUIC也有类似的机制)

[CUBIC](https://www.cs.princeton.edu/courses/archive/fall16/cos561/papers/Cubic08.pdf)  TCP传统的reno算法是每收到一个ACK就将发送窗口加一，或者在拥塞避免时收到所有ACK时才加一，在面对现在高速网络(大BDP)时，利用率很低。Cubic使用三次函数来调节，快速增长到0点附近时(以$$y = x ^ 3$$ 为例)，波动就比较小了。```/proc/sys/net/ipv4/tcp_congestion_control ``` 可查看Ubuntu20.04 默认使用Cubic

[BBR: Congestion-Based Congestion Control](https://queue.acm.org/detail.cfm?id=3022184) 一种新的拥塞控制算法，可以只部署在服务端。核心思想是尽可能让流量占满带宽时延积即可，而不是像传统算法一样一直打满直到丢包。BBR的好处是既充分利用带宽，又不增加额外延迟。



Linux中TCP实现:

* skb在创建的时候，就已经申请了最大的header空间，http://vger.kernel.org/~davem/skb_data.html



### 3. QUIC

个人觉得QUIC的主要特点是灵活，并且改造了一些TCP的设计，比如即使重传packet，其编号也是不一样的；内置TLS层，连接更安全，延迟更小；connection ID和IP无关，支持更好的连接迁移；同一条连接支持传输不同的stream等等，都是TCP没有的。

灵活在于QUIC运行在用户态，不需要修改内核。QUIC的包可以有很多控制信息，不像TCP header大小有限。QUIC可以选择各种底层的拥塞控制算法.

但是，个人觉得QUIC和TCP核心思想都是一样的，基于ACK确认，超时等机制的面向连接的可靠传输，只是具体实现方式不同。











